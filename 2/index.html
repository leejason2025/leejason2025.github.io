<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 180 Proj 2: Fun with Filters and Frequencies!</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Raleway:wght@400;700&display=swap');

        body {
            font-family: 'Raleway', sans-serif;
            margin: 2%;
            padding: 0 5%; 
            text-align: center;
            background-color: #E7E9F0;
            color: #051747;
        }

        .title-block {
            background-color: #081F62; 
            color: #E7E9F0;
            padding: 4% 2%; 
            margin-bottom: 3%;
            text-align: center;
        }

        h1 {
            font-size: 2.7em; 
            margin-bottom: 1%;
        }

        h2 {
            font-size: 2.2em;
            margin-bottom: 1%;
        }

        h3 {
            font-size: 1.8em;
        }

        section h2 {
            font-size: 1.8em; 
            margin-bottom: 2%;
            margin-top: 5%; 
            position: relative;
        }

        section h2::after {
            content: '';
            display: block;
            width: 10%;
            height: 3px;
            background-color: #081F62; 
            margin: 1% auto; 
        }

        section {
            margin-bottom: 3%;
        }

        .image-item {
            text-align: center;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        .image-container {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 7px;
            justify-items: center;
        }
        
        img {
            max-width: 100%;
            width: 400px;
            height: auto;
            border: 5px solid #535F80;
        }

        p {
            text-align: left;
            margin-bottom: 2%;
            font-size: 1.1em;
            line-height: 1.6em; 
        }
        #gaussian-laplacian-stacks .image-container {
        display: grid;
        grid-template-columns: 1fr; /* Only 1 image per row */
        gap: 20px; /* Increase space between the images */
        }
    
        #gaussian-laplacian-stacks img {
            width: 100%; /* Ensure each image takes up the full width of the container */
            height: auto; /* Maintain aspect ratio */
        }
    
        .image-item p {
            margin-top: 5px;
            text-align: center;
        }

    </style>
</head>
<body>
    <div class="title-block">
        <h1>CS 180 Project 2: Fun with Filters and Frequencies!</h1>
        <h2>Exploring Image Filters and Frequency Domain Techniques</h2>
        <h3>Jason Lee</h3>
    </div>
    
    <section id="finite-difference-operator">
        <h2>Finite Difference Operator</h2>
        <p>
            To start off this project, I used simple difference operators to compute the image gradients along the x and y axes for edge detection. 
            By applying convolution with D_x = [[1, -1]] and D_y = [[1], [-1]] to the "Cameraman" image, I obtained the partial derivatives I_x and I_y
             , which highlight vertical and horizontal edges, respectively. I then combined these gradients to calculate the overall gradient magnitude, 
            representing the strength of edges. The formula that I used for gradient magnitude was √ ((I_x)^2 + (I_y)^2). After testing different thresholds, I found that a value of 50 worked best for binarizing the gradient 
            magnitude, producing a binary edge map that effectively highlights the detected edges in the image.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/cameraman.png" alt="cameraman">
                <p>Original Image</p>
            </div>
            <div class="image-item">
                <img src="media/Partial_Derivative_in_X.jpg" alt="Partial_Derivative_in_X">
                <p>X-gradient</p>
            </div>
            <div class="image-item">
                <img src="media/Partial_Derivative_in_Y.jpg" alt="Partial_Derivative_in_Y">
                <p>Y-gradient</p>
            </div>
            <div class="image-item">
                <img src="media/Gradient_Magnitude.jpg" alt="gradient magnitude">
                <p>Magnitude of Gradient</p>
            </div>
            <div class="image-item">
                <img src="media/Binarized_Edge_Image.jpg" alt="edges">
                <p>Edges Detected</p>
            </div>
        </div>
    </section>

    <section id="dog-filter">
        <h2>Derivative of Gaussian (DoG) Filter</h2>
        <p>
            The Derivative of Gaussian (DoG) filter is an extension of the Gaussian blur, which smooths the image and computes the derivative. 
            This is useful for detecting edges in the image after reducing noise. Below are the images of the cameraman with a blurr applied and then the edge
            detection. Also, there is a second method of calculating the derivative of guassian filters to only use one convolution per direction.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/Cameraman_With_Blurr.jpg" alt="DoG Example 1">
                <p>Cameraman Blurred</p>
            </div>
            <div class="image-item">
                <img src="media/Binary_Edge_Image_With_Blurr.jpg" alt="DoG Example 2">
                <p>Binary Edge Image With Blurr</p>
            </div>
            <div class="image-item">
                <img src="media/Single_Convolution.jpg" alt="DoG Example 3">
                <p>DoG Applied</p>
            </div>
        </div>
        <p>
            After applying the blurr, we can see that there is a lot less noise which is extremely helpful for edge detection. Also, we know that by 
            the properties of convolution, we can use the derivative of guassians to convolve and get the same answers. This is confirmed by the example above.
        </p>
    </section>

    <section id="image-sharpening">
        <h2>Image "Sharpening"</h2>
        <p>
            In this section, I implemented a function to enhance image details by isolating and amplifying high-frequency components. 
            This was achieved by applying a Gaussian blur to the image, subtracting the blurred version to isolate the high frequencies, 
            and adding them back to the original image, scaled by a factor α. For color images, each RGB channel was sharpened 
            individually before recombining them. I tested this on the images of the Taj Mahal as well as a picture of a blurry road with trees.
            I also confirmed it worked by taking a non-blurry image of a city, applying a blur and then sharpening it.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/Taj_Original.jpg" alt="Sharpening Example 1">
                <p>Original Taj Mahal</p>
            </div>
            <div class="image-item">
                <img src="media/Taj_Sharpened.jpg" alt="Sharpening Example 2">
                <p>Taj Mahal Sharpened</p>
            </div>
        </div>
        <div class="image-container">
            <div class="image-item">
                <img src="media/Trees_Original.jpg" alt="Sharpening Example 3">
                <p>Original Blurry Road</p>
            </div>
            <div class="image-item">
                <img src="media/Trees_Sharpened.jpg" alt="Sharpening Example 4">
                <p>Blurry Road Sharpened</p>
            </div>
        </div>
        <div class="image-container">
            <div class="image-item">
                <img src="media/City_Original.jpg" alt="Sharpening Example 5">
                <p>Original City</p>
            </div>
            <div class="image-item">
                <img src="media/City_Blurred.jpg" alt="Sharpening Example 6">
                <p>City Blurred</p>
            </div>
            <div class="image-item">
                <img src="media/City_Sharpened.jpg" alt="Sharpening Example 7">
                <p>City Re-sharpened</p>
            </div>
        </div>
    </section>

    <section id="hybrid-images">
        <h2>Hybrid Images</h2>
        <p>
            I created a hybrid image by combining the low-frequency components of one image with the high-frequency components of another. 
            First, I applied a Gaussian blur to the first image ("Derek") to extract its low frequencies, and separately blurred the second 
            image ("Nutmeg") to isolate the high-frequency details by subtracting its blurred version from the original. The hybrid image was 
            then formed by adding the low-frequency content of the first image to the high-frequency content of the second, producing a result 
            where the viewer sees one image up close and another from a distance. After aligning the two images using a provided function, 
            I experimented with different blur levels to create the final hybrid image. This method blends the two images in a way that 
            shifts perception based on viewing distance.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/Top_Image_Nutmeg.jpg" alt="Hybrid Image 1">
                <p>Aligned Gray Nutmeg</p>
            </div>
            <div class="image-item">
                <img src="media/Base_Image_Derek.jpg" alt="Hybrid Image 2">
                <p>Aligned Gray Derek</p>
            </div>
            <div class="image-item">
                <img src="media/Hybrid_Derek_Nutmeg.jpg" alt="Hybrid Image 3">
                <p>Derek + Nutmeg</p>
            </div>
            <div class="image-item">
                <img src="media/Top_Image_Wolf.jpg" alt="Hybrid Image 4">
                <p>Aligned Gray Wolf</p>
            </div>
            <div class="image-item">
                <img src="media/Base_Image_Leonardo.jpg" alt="Hybrid Image 5">
                <p>Aligned Gray Leonardo</p>
            </div>
            <div class="image-item">
                <img src="media/Hybrid_Wolf_Leonardo.jpg" alt="Hybrid Image 6">
                <p>Leonardo + Wolf</p>
            </div>
            <div class="image-item">
                <img src="media/Top_Image_Hulk.jpg" alt="Hybrid Image 7">
                <p>Aligned Gray Hulk</p>
            </div>
            <div class="image-item">
                <img src="media/Base_Image_Ruffalo.jpg" alt="Hybrid Image 8">
                <p>Aligned Gray Ruffalo</p>
            </div>
            <div class="image-item">
                <img src="media/Hybrid_Hulk_Ruffalo.jpg" alt="Hybrid Image 9">
                <p>Ruffalo + Hulk</p>
            </div>
        </div>
    </section>

    <section id="fourier-analysis">
        <h2>Fourier Analysis</h2>
        <p>
            Next, I performed a Fourier Transform Analysis on images to visualize their frequency 
            components and observe the effects of filtering. I first implemented a function to compute the 2D Fast 
            Fourier Transform of an image using np.fft.fft2. The FFT converts the image from the spatial domain to the frequency domain, 
            where each point represents a specific frequency. I then shifted the zero frequency component to the center of the 
            spectrum using np.fft.fftshift and applied a logarithmic transformation to the magnitude to enhance the visibility 
            of the frequencies for display purposes. Next, I applied this FFT analysis to the images of "Ruffalo" and "Hulk" 
            to visualize their frequency content. After that, I used Gaussian filters to isolate the low-frequency components 
            in both images, displayed their filtered frequency spectra, and subtracted the low frequencies from the "Ruffalo" 
            image to obtain the high frequencies. Finally, I combined the low-frequency components of "Hulk" with the high-frequency 
            components of "Ruffalo" to create a hybrid image, and I displayed its frequency spectrum. This Fourier analysis allowed me 
            to explore how the combination of different frequency bands contributes to the resulting hybrid image, making the transitions
            between the two images more understandable in terms of their frequency characteristics.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/Hulk_FFT.jpg" alt="Fourier Analysis 1">
                <p>Hulk FFT</p>
            </div>
            <div class="image-item">
                <img src="media/Ruffalo_FFT.jpg" alt="Fourier Analysis 2">
                <p>Ruffalo FFT</p>
            </div>
            <div class="image-item">
                <img src="media/Hulk_Filtered_FFT.jpg" alt="Fourier Analysis 3">
                <p>Hulk Filtered FFT</p>
            </div>
            <div class="image-item">
                <img src="media/Ruffalo_Filtered_FFT.jpg" alt="Fourier Analysis 4">
                <p>Ruffalo Filtered FFT</p>
            </div>
            <div class="image-item">
                <img src="media/Hybrid_FFT.jpg" alt="Fourier Analysis 5">
                <p>Hybrid FFT</p>
            </div>
        </div>
    </section>

    <section id="gaussian-laplacian-stacks">
        <h2>Gaussian and Laplacian Stacks</h2>
        <p>
            In this section, I generated and visualized Gaussian and Laplacian Stacks for multi-resolution analysis of images.
            The Gaussian stack was created by progressively blurring the image at each level using a Gaussian filter with an 
            increasing sigma value, resulting in a series of images that become smoother at higher levels. The Laplacian stack
            was then formed by subtracting each blurred image from the next level in the Gaussian stack, isolating the high-frequency
            details between levels, with the final level representing the most blurred, low-frequency version of the image. I 
            applied this process to two grayscale images, "Apple" and "Orange," creating five levels for each image. The Gaussian 
            stack showed progressively blurred versions, while the Laplacian stack revealed finer details at each level. This 
            multi-resolution decomposition is useful for analyzing and manipulating images across different scales and frequencies.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/Orange_Guassian.jpg" alt="Stack Example 1">
                <p>Orange Gaussian Stack</p>
            </div>
            <div class="image-item">
                <img src="media/Orange_Laplacian.jpg" alt="Stack Example 2">
                <p>Orange Laplacian Stack</p>
            </div>
            <div class="image-item">
                <img src="media/Apple_Guassian.jpg" alt="Stack Example 3">
                <p>Apple Gaussian Stack</p>
            </div>
            <div class="image-item">
                <img src="media/Apple_Laplacian.jpg" alt="Stack Example 4">
                <p>Apple Laplacian Stack</p>
            </div>
        </div>
    </section>

    <section id="multiresolution-blending">
        <h2>Multiresolution Blending</h2>
        <p>
            In this section, I implemented multiresolution blending using Gaussian and Laplacian stacks to seamlessly merge images 
            based on different masks. First, I created three types of masks: vertical, horizontal, and circular, which define the 
            blending regions in the images. The blending process works by constructing Gaussian and Laplacian stacks for each image
            and the mask. The Gaussian stack progressively blurs the images at multiple levels, while the Laplacian stack isolates 
            the details between each level of the Gaussian stack, splitting the images into high and low-frequency components. To 
            blend two images, I applied the Laplacian stacks of both images to their respective color channels (RGB) and used the 
            Gaussian stack of the mask to smoothly combine the two Laplacian stacks. The blending is achieved by weighting each 
            image based on the mask, creating a transition between the two images. Finally, I reconstructed the blended image by 
            adding the frequency levels from the Laplacian stacks, producing the final composite. I tested this approach on three 
            image pairs: "Apple + Orange" using a vertical mask, "Night + River" using a horizontal mask, and "Itachi + Fire" using a circular mask.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="media/apple.jpeg" alt="Blending Example 1">
                <p>Apple</p>
            </div>
            <div class="image-item">
                <img src="media/orange.jpeg" alt="Blending Example 2">
                <p>Orange</p>
            </div>
            <div class="image-item">
                <img src="media/Apple + Orange.jpg" alt="Blending Example 3">
                <p>Apple + Orange</p>
            </div>
            <div class="image-item">
                <img src="media/itachi.jpg" alt="Blending Example 4">
                <p>Itachi</p>
            </div>
            <div class="image-item">
                <img src="media/fire.jpg" alt="Blending Example 5">
                <p>Fire</p>
            </div>
            <div class="image-item">
                <img src="media/Itachi_Fire.jpg" alt="Blending Example 6">
                <p>Itachi + Fire</p>
            </div>
            <div class="image-item">
                <img src="media/night.jpg" alt="Blending Example 7">
                <p>Night View</p>
            </div>
            <div class="image-item">
                <img src="media/river.jpg" alt="Blending Example 8">
                <p>River</p>
            </div>
            <div class="image-item">
                <img src="media/Night_River.jpg" alt="Blending Example 9">
                <p>Night + River</p>
            </div>
        </div>
    </section>
</body>
</html>
